"use client"
import React, { useEffect, useRef, useState } from 'react';
import { Card, CardContent } from "@/components/ui/card";
import { Alert, AlertDescription } from "@/components/ui/alert";
import { Button } from "@/components/ui/button";
import { Select, SelectTrigger, SelectValue, SelectContent, SelectItem } from "@/components/ui/select";

interface Emotion {
  score: number;
  name: string;
}

interface Expressions {
  [key: string]: number;
}

interface Props {
  videoRef: React.RefObject<HTMLVideoElement>;
  canvasRef: React.RefObject<HTMLCanvasElement>;
}

const VideoStream: React.FC<Props> = ({ videoRef, canvasRef }) => {
  const [expressions, setExpressions] = useState<Expressions | null>(null);
  const socketRef = useRef<WebSocket | null>(null);

  const streamRef = useRef<MediaStream | null>(null);
  const [isStreaming, setIsStreaming] = useState(false);
  const [devices, setDevices] = useState<MediaDeviceInfo[]>([]);
  const [status, setStatus] = useState("");

  useEffect(() => {
    console.log("Mounting component");
    console.log("Connecting to server");
    connect();

    return () => {
      console.log("Tearing down component");
      stopEverything();
    };
  }, []);


  function connect() {
    const socket = socketRef.current;
    if (socket && socket.readyState === WebSocket.OPEN) {
      console.log("Socket already exists, will not create");
    } else {
      setStatus(`Connecting to server...`);
      console.log(`Connecting to websocket...`);
      
      const socketUrl = `wss://api.hume.ai/v0/stream/models?api_key=${process.env.NEXT_PUBLIC_HUME_API_KEY}`;
      const socket = new WebSocket(socketUrl);

      socket.onopen = socketOnOpen;
      socket.onmessage = socketOnMessage;
      socket.onclose = socketOnClose;
      socket.onerror = socketOnError;

      socketRef.current = socket;
    }
  }

  async function socketOnOpen() {
    console.log("Connected to websocket");
    setStatus("Connecting to webcam...");
    // setIsStreaming(true);

  }

  async function socketOnMessage(event: MessageEvent) {
    const data = JSON.parse(event.data as string);
    if (data.face && data.face.predictions && data.face.predictions.length > 0) {
      const emotions: Emotion[] = data.face.predictions[0].emotions;
      const expressionsObj: Expressions = {};
      emotions.forEach((emotion: Emotion) => {
        expressionsObj[emotion.name] = emotion.score;
      });
      setExpressions(expressionsObj);
    }
  }

  async function socketOnClose(event: CloseEvent) {
    console.log("Socket closed : ", event);
  }

  async function socketOnError(event: Event) {
    console.error("Socket failed to connect: ", event);
  }

  function stopEverything() {
    console.log("Stopping everything...");
    // mountRef.current = false;
    const socket = socketRef.current;
    if (socket) {
      console.log("Closing socket");
      socket.close();
      socketRef.current = null;
    } else {
      console.warn("Could not close socket, not initialized yet");
    }
    // const recorder = recorderRef.current;
    // if (recorder) {
    //   console.log("Stopping recorder");
    //   recorder.stopRecording();
    //   recorderRef.current = null;
    // } else {
    //   console.warn("Could not stop recorder, not initialized yet");
    // }
  }


  useEffect(() => {
    navigator.mediaDevices.enumerateDevices().then(setDevices);
  }, []);

  const startVideoStream = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      streamRef.current = stream;
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }
      setIsStreaming(true)
      startSendingFrames();
    } catch (error) {
      console.error('Error accessing camera:', error);
    }
  };

  const stopVideoStream = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
    }
    // if (socketRef.current) {
    //   socketRef.current.close();
    // }
    setIsStreaming(false);
    setExpressions(null);
  };

  const startSendingFrames = () => {
    const sendVideoFrames = () => {
      if (videoRef.current && canvasRef.current && socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {
        const context = canvasRef.current.getContext('2d');
        if (context) {
          context.drawImage(videoRef.current, 0, 0, canvasRef.current.width, canvasRef.current.height);
          const imageData = canvasRef.current.toDataURL('image/jpeg', 0.8);
          const base64Data = imageData.split(',')[1];

          socketRef.current.send(JSON.stringify({
            data: base64Data,
            models: {
              face: {}
            }
          }));
        }
      }
    };

    const intervalId = setInterval(sendVideoFrames, 1000);
    return () => clearInterval(intervalId);
  };

  return (
    <Card className="max-w-md mx-auto">
      <CardContent>
        <Alert variant="default" className="mb-4">
          <AlertDescription>
            Streaming API Status: {isStreaming ? 'Connected' : 'Disconnected'}
          </AlertDescription>
        </Alert>

        <p>{status}</p>
        <div className="relative">
          <video ref={videoRef} autoPlay playsInline muted className="w-full aspect-video mb-4" />
          <canvas ref={canvasRef} style={{ display: 'none' }} width={640} height={480} />
          
          {isStreaming && (
            <Button 
              variant="destructive" 
              size="sm" 
              className="absolute bottom-2 left-2"
              onClick={stopVideoStream}
            >
              Stop
            </Button>
          )}
        </div>

        <div className="flex space-x-2 mb-4">
          <Select>
            <SelectTrigger>
              <SelectValue placeholder="Select camera" />
            </SelectTrigger>
            <SelectContent>
              {devices.filter(device => device.kind === 'videoinput').map(device => (
                <SelectItem key={device.deviceId} value={device.deviceId}>
                  {device.label || `Camera ${device.deviceId.slice(0, 5)}`}
                </SelectItem>
              ))}
            </SelectContent>
          </Select>
          <Select>
            <SelectTrigger>
              <SelectValue placeholder="Select microphone" />
            </SelectTrigger>
            <SelectContent>
              {devices.filter(device => device.kind === 'audioinput').map(device => (
                <SelectItem key={device.deviceId} value={device.deviceId}>
                  {device.label || `Microphone ${device.deviceId.slice(0, 5)}`}
                </SelectItem>
              ))}
            </SelectContent>
          </Select>
        </div>

        {!isStreaming && (
          <Button onClick={startVideoStream}>Start Stream</Button>
        )}

        {expressions && (
          <div className="mt-4">
            <h2 className="text-lg font-semibold mb-2">Facial Expressions:</h2>
            <ul>
              {Object.entries(expressions).map(([emotion, score]) => (
                <li key={emotion} className="mb-1">
                  {emotion}: {score.toFixed(2)}
                </li>
              ))}
            </ul>
          </div>
        )}
      </CardContent>
    </Card>
  );
};

export default VideoStream;



















//@ts-check
"use client"

import React, { useEffect, useRef } from "react";
import VideoStream from "@/components/VideoStream";
import Image from "next/image";
import AudioStreamingComponent from "@/components/AudioStream";

export default function Home() {
  // const videoRef = useRef<HTMLVideoElement>(null);
  // const canvasRef = useRef<HTMLCanvasElement>(null);
  // const streamRef = useRef<MediaStream | null>(null);

  // const mediaRecorderRef = useRef<MediaRecorder | null>(null);



  // useEffect(() => {
  //   startVideoStream();
  //   return () => {
  //     console.log("Tearing down component");
  //   };
  // }, []);

  // const startVideoStream = async () => {
  //   try {
  //     const stream = await navigator.mediaDevices.getUserMedia({ video: true });
  //     streamRef.current = stream;
  //     if (videoRef.current) {
  //       videoRef.current.srcObject = stream;
  //     }
  //     // startSendingFrames();
  //   } catch (error) {
  //     console.error('Error accessing camera:', error);
  //   }
  // };


  return (
    <div>
      {/* <h1>Facial Expression Analysis</h1>

        <div className="relative max-w-md mx-auto">
          <video ref={videoRef} autoPlay playsInline muted className="w-full aspect-video mb-4" />
          <canvas ref={canvasRef} style={{ display: 'none' }} width={640} height={480} />
        </div> */}
      {/* <VideoStream videoRef={videoRef} canvasRef={canvasRef}  /> */}
      <AudioStreamingComponent modelName="prosody" recordingLengthMs={500} streamWindowLengthMs={5000} />
    
    </div>
  );
}
